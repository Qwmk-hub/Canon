import torch
from torchvision import models, transforms
from PIL import Image
import os
from model.mobilenetv2 import get_mobilenet
from model.efficientnet import get_efficientnet_b1, get_efficientnet_b2
from torch.nn.functional import softmax
import time

# ì„¤ì •
input_folder = "data/1cycle_image"  # ë¶„ë¥˜í•  ì´ë¯¸ì§€ í´ë”
model_path = "outputs/best_1_model_b1.pth"
class_order = ["target_1", "target_2", "target_3", "target_4"]

# 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model = get_mobilenet(num_classes=5)
model = get_efficientnet_b1(num_classes=4)
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval().to(device)

# 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# 3. í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ ì´ë¦„ ë§¤í•‘ (ImageFolderì—ì„œ class_to_idx ê¸°ì¤€)
class_names = ["target_1", "target_2", "target_3", "target_4"]

# 4. ì´ë¯¸ì§€ ìˆœì°¨ì ìœ¼ë¡œ ì˜ˆì¸¡
predicted_sequence = []
image_files = sorted(os.listdir(input_folder))

total_inference_time = 0

for img_name in image_files:
    img_path = os.path.join(input_folder, img_name)
    image = Image.open(img_path).convert("RGB")
    input_tensor = transform(image).unsqueeze(0).to(device)

    start_time = time.time()

    with torch.no_grad():
        output = model(input_tensor)
        probs = softmax(output, dim=1)
        max_prob = probs.max().item()
        pred_idx = probs.argmax(1).item()

        end_time = time.time()  # âœ… ë ì‹œê°„ ê¸°ë¡
        inference_time = end_time - start_time
        total_inference_time += inference_time  # âœ… ëˆ„ì 

        if max_prob >= 0.450 and pred_idx < len(class_names): # best_1,2 : 0.45 / best_3 : 0.93
            pred_label = class_names[pred_idx]
        else:
            pred_label = "pass"
        predicted_sequence.append(pred_label)

# ì˜ˆì¸¡ëœ ì‹œí€€ìŠ¤ ì¶œë ¥
print("ğŸ” ì˜ˆì¸¡ëœ ì‹œí€€ìŠ¤:")
for img_name, label in zip(image_files, predicted_sequence):
    print(f"{img_name}: {label}")

# 5. ìˆœì°¨ì ì¸ target í™•ì¸ (ì •í™•í•œ ìˆœì„œ ìœ ì§€ í•„ìš”)
target_idx = 0
for label in predicted_sequence:
    if label == class_order[target_idx]:
        target_idx += 1
        if target_idx == len(class_order):
            break
    elif label in class_order[target_idx+1:]:
        # ìˆœì„œ ì–´ê¸‹ë‚œ ê²½ìš° â†’ ë°”ë¡œ FAIL
        target_idx = -1
        break

# 6. ê²°ê³¼ ì¶œë ¥
if target_idx == len(class_order):
    print("âœ… PASS: ëª¨ë“  íƒ€ê²Ÿì´ ìˆœì°¨ì ìœ¼ë¡œ ê°ì§€ë¨!")
else:
    print("âŒ FAIL: ìˆœì„œëŒ€ë¡œ ê°ì§€ë˜ì§€ ì•ŠìŒ.")

avg_time = total_inference_time / len(image_files)
print(f"\nâ±ï¸ ì „ì²´ Inference ì‹œê°„: {total_inference_time:.4f}ì´ˆ")
print(f"â±ï¸ ì´ë¯¸ì§€ë‹¹ í‰ê·  Inference ì‹œê°„: {avg_time:.4f}ì´ˆ")
